# SadTalker/inference.py

from glob import glob
import shutil
import torch
from time import strftime
import os, sys, time
from argparse import Namespace # Use Namespace to mimic argparse.parse_args()
import tempfile # For creating temporary files and directories
import io # For reading binary data into memory
from typing import List
import logging # Import logging module

# Configure logging for better visibility
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Import your SadTalker components
# Adjust sys.path.append to point to the directory containing 'src'
# If inference.py is directly in SadTalker/, then 'src' is also directly in SadTalker/
current_file_dir = os.path.dirname(os.path.abspath(__file__)) # This is now SadTalker/
sadtalker_root_path = current_file_dir # The SadTalker root is where inference.py is

sys.path.append(sadtalker_root_path) # Add SadTalker/ to path to find src/

try:
    from src.utils.preprocess import CropAndExtract
    from src.test_audio2coeff import Audio2Coeff
    from src.facerender.animate import AnimateFromCoeff
    from src.generate_batch import get_data
    from src.generate_facerender_batch import get_facerender_data
    from src.utils.init_path import init_path
    logger.info("Successfully imported SadTalker components.")
except ImportError as e:
    logger.error(f"Failed to import SadTalker components. Ensure SadTalker's 'src' directory is in PYTHONPATH relative to {sadtalker_root_path}. Error: {e}")
    sys.exit(1) # Exit if core components can't be loaded

# --- Global Model Initialization Variables ---
# These will hold the loaded model instances.
# They are initialized to None and will be loaded once by initialize_sadtalker_models.
GLOBAL_PREPROCESS_MODEL = None
GLOBAL_AUDIO_TO_COEFF_MODEL = None
GLOBAL_ANIMATE_FROM_COEFF_MODEL = None
GLOBAL_SADTALKER_PATHS = None # To store the paths object generated by init_path

logger.info(f"Detected SadTalker root path: {sadtalker_root_path}")

DEFAULT_CHECKPOINT_DIR = os.path.join(sadtalker_root_path, 'checkpoints') # Adjust this path
DEFAULT_CONFIG_DIR = os.path.join(sadtalker_root_path, 'src/config')      # Adjust this path
DEFAULT_BFM_FOLDER = os.path.join(DEFAULT_CHECKPOINT_DIR, 'BFM_Fitting')

# --- Function to initialize models globally ---
def initialize_sadtalker_models(
    device: str,
    checkpoint_dir: str = DEFAULT_CHECKPOINT_DIR,
    config_dir: str = DEFAULT_CONFIG_DIR,
    size: int = 256,
    old_version: bool = False,
    preprocess_type: str = 'crop'
):
    """
    Initializes SadTalker models globally. This function should be called ONCE
    when your application starts (e.g., in a FastAPI app's @app.on_event("startup")
    or similar entry point).
    """
    global GLOBAL_PREPROCESS_MODEL, GLOBAL_AUDIO_TO_COEFF_MODEL, GLOBAL_ANIMATE_FROM_COEFF_MODEL, GLOBAL_SADTALKER_PATHS

    if GLOBAL_PREPROCESS_MODEL is not None:
        logger.info("SadTalker models already initialized globally. Skipping re-initialization.")
        return

    logger.info(f"Globally initializing SadTalker models on device: {device}")
    try:
        GLOBAL_SADTALKER_PATHS = init_path(
            checkpoint_dir,
            config_dir,
            size,
            old_version,
            preprocess_type
        )
        GLOBAL_PREPROCESS_MODEL = CropAndExtract(GLOBAL_SADTALKER_PATHS, device)
        GLOBAL_AUDIO_TO_COEFF_MODEL = Audio2Coeff(GLOBAL_SADTALKER_PATHS, device)
        GLOBAL_ANIMATE_FROM_COEFF_MODEL = AnimateFromCoeff(GLOBAL_SADTALKER_PATHS, device)
        logger.info("SadTalker models successfully initialized globally.")
    except Exception as e:
        logger.error(f"FATAL ERROR: Failed to initialize SadTalker models globally. Please check paths and dependencies. Error: {e}")
        # Optionally, you might want to raise an exception or exit here
        raise RuntimeError(f"Global SadTalker model initialization failed: {e}")

# --- Original main function, adapted to work with an 'args' Namespace ---
def _run_sadtalker_main(args: Namespace) -> bytes:
    """
    Internal function that wraps the original SadTalker main logic.
    It takes a Namespace object similar to what argparse would create.
    Returns the raw bytes of the generated video.
    """
    logger.info("Starting _run_sadtalker_main with provided arguments.")

    # Assert that global models are initialized
    if GLOBAL_PREPROCESS_MODEL is None or GLOBAL_AUDIO_TO_COEFF_MODEL is None or GLOBAL_ANIMATE_FROM_COEFF_MODEL is None:
        logger.error("SadTalker models are not initialized globally. Call initialize_sadtalker_models first.")
        raise RuntimeError("SadTalker models not initialized.")

    pic_path = args.source_image
    audio_path = args.driven_audio
    save_dir = os.path.join(args.result_dir, strftime("%Y_%m_%d_%H.%M.%S"))
    os.makedirs(save_dir, exist_ok=True)
    pose_style = args.pose_style
    batch_size = args.batch_size
    input_yaw_list = args.input_yaw
    input_pitch_list = args.input_pitch
    input_roll_list = args.input_roll
    ref_eyeblink = args.ref_eyeblink
    ref_pose = args.ref_pose
    
    current_device = args.device # Get the device from the passed args

    logger.info(f"Input image path: {pic_path}")
    logger.info(f"Input audio path: {audio_path}")
    logger.info(f"Save directory: {save_dir}")
    logger.info(f"Pose style: {pose_style}, Batch size: {batch_size}")
    logger.info(f"Running inference on device: {current_device}")

    # Validate input paths exist
    if not os.path.exists(pic_path):
        raise FileNotFoundError(f"Source image not found: {pic_path}")
    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"Driven audio not found: {audio_path}")

    # --- Use the globally initialized models ---
    logger.info("Using globally initialized SadTalker models for current inference request.")

    # crop image and extract 3dmm from image
    first_frame_dir = os.path.join(save_dir, 'first_frame_dir')
    os.makedirs(first_frame_dir, exist_ok=True)
    logger.info('3DMM Extraction for source image')
    try:
        first_coeff_path, crop_pic_path, crop_info = GLOBAL_PREPROCESS_MODEL.generate(
            pic_path, first_frame_dir, args.preprocess,
            source_image_flag=True, pic_size=args.size
        )
    except Exception as e:
        logger.error(f"Error during 3DMM extraction for source image: {e}")
        raise ValueError(f"Failed 3DMM extraction for source image: {e}")

    if first_coeff_path is None or not os.path.exists(first_coeff_path):
        logger.error(f"first_coeff_path is invalid: {first_coeff_path}")
        raise ValueError("Can't get the coeffs of the input image. Please check the image file or preprocess settings.")
    logger.info(f"first_coeff_path: {first_coeff_path}")
    logger.info(f"crop_pic_path: {crop_pic_path}")

    # Handle reference eyeblink and pose
    ref_eyeblink_coeff_path = None
    if ref_eyeblink is not None:
        logger.info(f"Reference eyeblink video: {ref_eyeblink}")
        if not os.path.exists(ref_eyeblink):
            logger.warning(f"Reference eyeblink video not found: {ref_eyeblink}. Proceeding without it.")
        else:
            ref_eyeblink_videoname = os.path.splitext(os.path.split(ref_eyeblink)[-1])[0]
            ref_eyeblink_frame_dir = os.path.join(save_dir, ref_eyeblink_videoname)
            os.makedirs(ref_eyeblink_frame_dir, exist_ok=True)
            logger.info('3DMM Extraction for the reference video providing eye blinking')
            try:
                ref_eyeblink_coeff_path, _, _ = GLOBAL_PREPROCESS_MODEL.generate(ref_eyeblink, ref_eyeblink_frame_dir, args.preprocess, source_image_flag=False)
                if ref_eyeblink_coeff_path is None or not os.path.exists(ref_eyeblink_coeff_path):
                    logger.warning(f"Could not extract coeffs for reference eyeblink video: {ref_eyeblink}. Proceeding without it.")
                    ref_eyeblink_coeff_path = None
                else:
                    logger.info(f"ref_eyeblink_coeff_path: {ref_eyeblink_coeff_path}")
            except Exception as e:
                logger.warning(f"Error extracting eyeblink coeffs from {ref_eyeblink}: {e}. Proceeding without it.")
                ref_eyeblink_coeff_path = None

    ref_pose_coeff_path = None
    if ref_pose is not None:
        logger.info(f"Reference pose video: {ref_pose}")
        if ref_pose == ref_eyeblink:
            ref_pose_coeff_path = ref_eyeblink_coeff_path
        else:
            if not os.path.exists(ref_pose):
                logger.warning(f"Reference pose video not found: {ref_pose}. Proceeding without it.")
            else:
                ref_pose_videoname = os.path.splitext(os.path.split(ref_pose)[-1])[0]
                ref_pose_frame_dir = os.path.join(save_dir, ref_pose_videoname)
                os.makedirs(ref_pose_frame_dir, exist_ok=True)
                logger.info('3DMM Extraction for the reference video providing pose')
                try:
                    ref_pose_coeff_path, _, _ = GLOBAL_PREPROCESS_MODEL.generate(ref_pose, ref_pose_frame_dir, args.preprocess, source_image_flag=False)
                    if ref_pose_coeff_path is None or not os.path.exists(ref_pose_coeff_path):
                        logger.warning(f"Could not extract coeffs for reference pose video: {ref_pose}. Proceeding without it.")
                        ref_pose_coeff_path = None
                    else:
                        logger.info(f"ref_pose_coeff_path: {ref_pose_coeff_path}")
                except Exception as e:
                    logger.warning(f"Error extracting pose coeffs from {ref_pose}: {e}. Proceeding without it.")
                    ref_pose_coeff_path = None

    # audio2ceoff
    logger.info('Generating coefficients from audio.')
    try:
        batch = get_data(first_coeff_path, audio_path, current_device, ref_eyeblink_coeff_path, still=args.still)
        coeff_path = GLOBAL_AUDIO_TO_COEFF_MODEL.generate(batch, save_dir, pose_style, ref_pose_coeff_path)
    except Exception as e:
        logger.error(f"Error during audio to coefficient generation: {e}")
        raise ValueError(f"Failed audio to coefficient generation: {e}")

    if coeff_path is None or not os.path.exists(coeff_path):
        logger.error(f"coeff_path is invalid: {coeff_path}")
        raise ValueError("Failed to generate coefficients from audio.")
    logger.info(f"Generated coeff_path: {coeff_path}")


    # 3dface render (optional, only if args.face3dvis is True)
    if args.face3dvis:
        logger.info('Generating 3D face visualization.')
        try:
            from src.face3d.visualize import gen_composed_video
            gen_composed_video(args, current_device, first_coeff_path, coeff_path, audio_path, os.path.join(save_dir, '3dface.mp4'))
        except Exception as e:
            logger.warning(f"Error generating 3D face visualization: {e}")


    # coeff2video
    logger.info('Rendering video from coefficients.')
    try:
        data = get_facerender_data(coeff_path, crop_pic_path, first_coeff_path, audio_path,
                                    batch_size, input_yaw_list, input_pitch_list, input_roll_list,
                                    expression_scale=args.expression_scale, still_mode=args.still, preprocess=args.preprocess, size=args.size)
        logger.info(f"Facerender data prepared. Batch size: {len(data)}")

        generated_video_path = GLOBAL_ANIMATE_FROM_COEFF_MODEL.generate(data, save_dir, pic_path, crop_info,
                                                                  enhancer=args.enhancer, background_enhancer=args.background_enhancer, preprocess=args.preprocess, img_size=args.size)
    except Exception as e:
        logger.error(f"Error during video rendering from coefficients: {e}")
        # Log the types of the inputs to animate_from_coeff.generate
        logger.error(f"Debug: type(data)={type(data)}, type(save_dir)={type(save_dir)}, type(pic_path)={type(pic_path)}, type(crop_info)={type(crop_info)}")
        raise ValueError(f"Failed to render video from coefficients: {e}")

    if generated_video_path is None or not os.path.exists(generated_video_path):
        logger.error(f"Generated video path is invalid: {generated_video_path}")
        raise ValueError("Failed to generate video output.")
    logger.info(f"Generated video path: {generated_video_path}")

    final_output_path = save_dir + '.mp4'
    try:
        shutil.move(generated_video_path, final_output_path)
    except Exception as e:
        logger.error(f"Error moving generated video from {generated_video_path} to {final_output_path}: {e}")
        try:
            shutil.copy(generated_video_path, final_output_path)
            os.remove(generated_video_path)
        except Exception as copy_e:
            logger.error(f"Fallback copy/delete also failed: {copy_e}")
            raise RuntimeError(f"Could not finalize video output: {e}, {copy_e}")

    logger.info('The generated video is named: %s', final_output_path)

    # Read the generated video file into bytes
    with open(final_output_path, 'rb') as f:
        video_bytes = f.read()

    # Clean up temporary directory if verbose is False
    if not args.verbose:
        logger.info(f"Cleaning up temporary directory: {save_dir}")
        shutil.rmtree(save_dir)
        # Also remove the final .mp4 file after reading its content
        if os.path.exists(final_output_path):
            os.remove(final_output_path)
            logger.info(f"Cleaned up {final_output_path}")

    logger.info("Inference completed successfully.")
    return video_bytes


# --- Public facing function for FastAPI ---
def run_lipsync_inference_from_bytes(
    image_bytes: bytes,
    audio_bytes: bytes,
    enhancer: str = None,
    pose_style: int = 0,
    batch_size: int = 2,
    size: int = 256,
    expression_scale: float = 1.0,
    input_yaw: List[int] = None,
    input_pitch: List[int] = None,
    input_roll: List[int] = None,
    ref_eyeblink: str = None,
    ref_pose: str = None,
    face3dvis: bool = False,
    still: bool = False,
    preprocess: str = 'crop',
    verbose: bool = False,
    old_version: bool = False,
    net_recon: str = 'resnet50',
    init_path_arg: str = None, # This argument is now less relevant for global init, but kept for compatibility
    use_last_fc: bool = False,
    bfm_folder: str = DEFAULT_BFM_FOLDER,
    bfm_model: str = 'BFM_model_front.mat',
    focal: float = 1015.,
    center: float = 112.,
    camera_d: float = 10.,
    z_near: float = 5.,
    z_far: float = 15.,
    use_cpu: bool = False,
) -> bytes:
    logger.info("Received request for run_lipsync_inference_from_bytes.")

    # Determine the device based on user preference and availability
    if use_cpu:
        inference_device = "cpu"
        logger.info("User requested CPU usage.")
    elif torch.cuda.is_available():
        inference_device = "cuda"
        logger.info("CUDA is available, using GPU.")
    else:
        inference_device = "cpu"
        logger.warning("CUDA is not available, falling back to CPU.")
    
    # IMPORTANT: Initialize models if they haven't been already.
    # This call is now inside run_lipsync_inference_from_bytes, but ideally,
    # in a production web app, you would call initialize_sadtalker_models()
    # once at application startup. Placing it here makes it work, but
    # repeated calls will log "models already initialized".
    initialize_sadtalker_models(
        device=inference_device,
        checkpoint_dir=DEFAULT_CHECKPOINT_DIR,
        config_dir=DEFAULT_CONFIG_DIR,
        size=size, # Use the size from arguments for init
        old_version=old_version, # Use old_version from arguments for init
        preprocess_type=preprocess # Use preprocess from arguments for init
    )


    # Store temporary files
    with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as temp_image_file:
        temp_image_file.write(image_bytes)
        temp_image_path = temp_image_file.name
    logger.info(f"Temporary image saved to: {temp_image_path}")

    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_audio_file:
        temp_audio_file.write(audio_bytes)
        temp_audio_path = temp_audio_file.name
    logger.info(f"Temporary audio saved to: {temp_audio_path}")

    temp_result_dir = tempfile.mkdtemp()
    logger.info(f"Temporary result directory: {temp_result_dir}")

    # Ensure default values for lists if not provided
    if input_yaw is None: input_yaw = [0]
    if input_pitch is None: input_pitch = [0]
    if input_roll is None: input_roll = [0]

    try:
        args = Namespace(
            driven_audio=temp_audio_path,
            source_image=temp_image_path,
            ref_eyeblink=ref_eyeblink,
            ref_pose=ref_pose,
            checkpoint_dir=DEFAULT_CHECKPOINT_DIR, # Not used for init directly now, but kept for context
            result_dir=temp_result_dir,
            pose_style=pose_style,
            batch_size=batch_size,
            size=size,
            expression_scale=expression_scale,
            input_yaw=input_yaw,
            input_pitch=input_pitch,
            input_roll=input_roll,
            enhancer=enhancer,
            background_enhancer=None,
            cpu=use_cpu,
            face3dvis=face3dvis,
            still=still,
            preprocess=preprocess,
            verbose=verbose,
            old_version=old_version,
            net_recon=net_recon,
            init_path=init_path_arg,
            use_last_fc=use_last_fc,
            bfm_folder=bfm_folder,
            bfm_model=bfm_model,
            focal=focal,
            center=center,
            camera_d=camera_d,
            z_near=z_near,
            z_far=z_far,
            device=inference_device # Pass the determined device here
        )

        logger.info("Calling _run_sadtalker_main with constructed args.")
        video_output_bytes = _run_sadtalker_main(args)
        logger.info("SadTalker inference completed successfully.")
        return video_output_bytes

    finally:
        # Clean up temporary files
        if os.path.exists(temp_image_path):
            os.remove(temp_image_path)
            logger.info(f"Cleaned up {temp_image_path}")
        if os.path.exists(temp_audio_path):
            os.remove(temp_audio_path)
            logger.info(f"Cleaned up {temp_audio_path}")
        if os.path.exists(temp_result_dir):
            try:
                shutil.rmtree(temp_result_dir)
            except OSError as e:
                logger.warning(f"Failed to remove temp_result_dir {temp_result_dir}: {e}")
