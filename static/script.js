// Global DOM elements
const socket = new WebSocket("ws://localhost:8000/ws/lipsync");
const notificationDiv = document.getElementById("notification");
const imageInput = document.getElementById("imageInput");
const enhanceFaceCheckbox = document.getElementById("enhanceFaceCheckbox");
const outputVideo = document.getElementById("outputVideo");
const startRecordingButton = document.getElementById("startRecordingButton");
const stopRecordingButton = document.getElementById("stopRecordingButton");
const recordedAudioPlayback = document.getElementById("recordedAudioPlayback");
const playRecordedAudioButton = document.getElementById("playRecordedAudioButton");
const startLipSyncButton = document.getElementById("startLipSyncButton");
// Removed playOutputVideoButton as it's no longer needed for auto-play

// MediaRecorder and Audio related state
let mediaRecorder;
let audioChunks = [];
let recordedAudioBlob = null;

// MediaSource API related state
let mediaSource = null;
let videoSourceBuffer = null;
let audioSourceBuffer = null;
let segmentQueue = [];
let isMediaSourceOpen = false;
let appendingInProgress = false; // Tracks if a SourceBuffer.appendBuffer is ongoing
let mediaSourceUrl = null; // Store the URL generated by URL.createObjectURL

// Playback initialization flags
let videoInitReceived = false;
let audioInitReceived = false;
let hasAttemptedVideoPlayback = false; // Ensures outputVideo.play() is called only once
let mediaSourceInitialized = false; // Track if MediaSource is initialized for this session

// Other state variables
let notificationTimeout;
let isAudioStreamReady = false; // Indicates if server is ready to receive audio chunks


// --- Utility Functions ---
function showNotification(msg, type = "status-message", duration = 3000) {
    clearTimeout(notificationTimeout);
    notificationDiv.textContent = msg;
    notificationDiv.className = `notification-message ${type}`;
    notificationDiv.classList.remove("notification-hidden");
    if (duration > 0) {
        notificationTimeout = setTimeout(() => {
            notificationDiv.classList.add("notification-hidden");
            setTimeout(() => notificationDiv.textContent = "", 300);
        }, duration);
    }
}

function getBase64(fileOrBlob) {
    return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.readAsDataURL(fileOrBlob);
        reader.onload = () => {
            const base64String = reader.result.split(',')[1];
            resolve(base64String);
        };
        reader.onerror = error => reject(error);
    });
}

// --- WebSocket Event Handlers ---
socket.onopen = function(e) {
    console.log("WebSocket Connection established.");
    showNotification("Connection established. Select an image and click '1. Send Image & Initialize' to begin.", "success-message", 5000);
    resetUIForNewSession(); // Ensure UI is reset on connection
};

socket.onmessage = async function(event) {
    if (typeof event.data === 'string') {
        try {
            const serverMessage = JSON.parse(event.data);
            if (serverMessage.video_segment_base64 && serverMessage.segment_type && serverMessage.stream_type) {
                const segmentDataUint8Array = new Uint8Array(window.base64js.toByteArray(serverMessage.video_segment_base64));
                const segmentObj = {
                    data: segmentDataUint8Array,
                    segment_type: serverMessage.segment_type,
                    stream_type: serverMessage.stream_type,
                    segment_number: serverMessage.video_segment_number // Assuming this exists for debugging
                };
                segmentQueue.push(segmentObj);
                console.log(`Enqueued ${segmentObj.stream_type} ${segmentObj.segment_type} segment #${segmentObj.segment_number}. Queue size: ${segmentQueue.length}`);

                // Only initialize MediaSource ONCE per session
                if (!mediaSourceInitialized) {
                    console.log("Calling initializeMediaSource() for the first time in this session.");
                    initializeMediaSource();
                    mediaSourceInitialized = true; // Set the flag immediately
                }
                appendNextVideoSegment(); // Try to append immediately

                if (serverMessage.is_final_audio_chunk) {
                    showNotification("Server finished processing all audio. Finalizing video playback.", "success-message", 5000);
                }
            } else if (serverMessage.error) {
                showNotification(`Server Error: ${serverMessage.error}`, "error-message", 0);
                console.error("Server Error:", serverMessage.error);
                if (mediaSource && mediaSource.readyState === 'open') {
                    try { mediaSource.endOfStream('network'); } catch(e) { console.warn("Error ending MediaSource on server error:", e); }
                }
                resetUIForNewSession();
            } else {
                showNotification(`Server update: ${JSON.stringify(serverMessage)}`, "status-message", 3000);
                console.log("Server JSON update:", serverMessage);
            }
        } catch (e) {
            if (e instanceof SyntaxError) {
                const plainTextMessage = event.data;
                console.log("Received plain text message:", plainTextMessage); // Log all plain text messages

                if (plainTextMessage.includes("Ready. Send 'image_init'")) {
                    showNotification("Server ready. Please select an image and click '1. Send Image & Initialize'.", "info-message", 5000);
                } else if (plainTextMessage.includes("Image received")) {
                    showNotification("Image received. Click '2. Start Recording Audio' to begin audio input.", "success-message", 0);
                    startRecordingButton.disabled = false; // Enable audio recording button
                } else if (plainTextMessage.includes("Audio stream initiated")) {
                    showNotification("Audio stream started on server. Starting audio recording now.", "info-message", 3000);
                    isAudioStreamReady = true;
                    // Start mediaRecorder if it's not already recording.
                    // The .start(500) argument means it will chunk audio every 500ms.
                    if (mediaRecorder && mediaRecorder.state === 'inactive') {
                        mediaRecorder.start(500);
                        console.log("MediaRecorder started.");
                    } else if (mediaRecorder && mediaRecorder.state === 'recording') {
                        console.log("MediaRecorder already recording, skipping start.");
                    } else {
                        console.error("MediaRecorder not initialized or in unexpected state when audio stream initiated.");
                    }
                } else if (plainTextMessage.includes("Audio stream ended")) {
                    showNotification("Audio stream ended. Server is finalizing video...", "info-message", 0);
                    isAudioStreamReady = false;
                } else if (plainTextMessage.includes("Enqueued audio segment")) {
                    showNotification(plainTextMessage, "status-message", 3000);
                } else {
                    showNotification(plainTextMessage, "status-message", 3000);
                }
            } else {
                showNotification(`Client Error processing message: ${e.message}`, "error-message", 0);
                console.error("Client Error processing WebSocket message:", e);
                // No reset here, as it might be a temporary issue, only for critical errors.
            }
        }
    } else {
        showNotification(`Received unexpected data type from server: ${typeof event.data}`, "error-message", 0);
        console.warn("Received unexpected data type from WebSocket:", typeof event.data);
    }
};

socket.onclose = function(event) {
    if (event.wasClean) {
        showNotification("Connection closed cleanly.", "status-message", 5000);
        console.log(`Connection closed cleanly, code=${event.code}, reason=${event.reason}`);
    } else {
        showNotification('Connection died unexpectedly. Please refresh the page.', "error-message", 0);
        console.error('Connection died unexpectedly (code=' + event.code + ').');
    }
    resetUIForNewSession();
};

socket.onerror = function(error) {
    showNotification(`WebSocket Error: Check server connection.`, "error-message", 0);
    console.error("WebSocket Error:", error);
    resetUIForNewSession();
};


// --- MediaSource API for Video Streaming ---
function initializeMediaSource() {
    // This check ensures we don't try to re-initialize an already open MediaSource
    if (mediaSource && mediaSource.readyState === 'open') {
        console.warn("initializeMediaSource() called but MediaSource is already open. Skipping.");
        return;
    }
    if (mediaSourceInitialized) { // Double check using the new flag
        console.warn("initializeMediaSource() called but mediaSourceInitialized is already true. Skipping.");
        return;
    }

    mediaSource = new MediaSource();
    // CRITICAL: Set outputVideo.src only ONCE to the MediaSource object URL
    mediaSourceUrl = URL.createObjectURL(mediaSource); // Store the URL
    outputVideo.src = mediaSourceUrl;
    outputVideo.style.display = 'block'; // Make video element visible
    outputVideo.muted = true; // NEW: Start muted for better autoplay chances
    console.log("New MediaSource created and assigned to outputVideo.src.");

    mediaSource.addEventListener('sourceopen', () => {
        isMediaSourceOpen = true;
        console.log("MediaSource 'sourceopen' event fired. MediaSource readyState:", mediaSource.readyState);
        try {
            // Add SourceBuffers. Make sure mime types and codecs match your server's output.
            // These are common H.264 video and AAC audio in MP4 containers.
            // You might want to feature-detect these for broader compatibility if issues arise.
            videoSourceBuffer = mediaSource.addSourceBuffer('video/mp4; codecs="avc1.42E01E"');
            audioSourceBuffer = mediaSource.addSourceBuffer('audio/mp4; codecs="mp4a.40.2"');

            console.log("Video and Audio SourceBuffers added.");

            videoSourceBuffer.addEventListener('updateend', () => {
                appendingInProgress = false;
                console.log("Video SourceBuffer 'updateend'. Processing next segment.");
                appendNextVideoSegment();
            });
            videoSourceBuffer.addEventListener('error', (e) => {
                console.error("Video SourceBuffer error:", e);
                showNotification("Video playback error. Please try again.", "error-message", 0);
                if (mediaSource && mediaSource.readyState === 'open') {
                    try { mediaSource.endOfStream('decode'); } catch(err) { console.warn("Error ending MediaSource on video SB error:", err); }
                }
                resetUIForNewSession();
            });

            audioSourceBuffer.addEventListener('updateend', () => {
                appendingInProgress = false;
                console.log("Audio SourceBuffer 'updateend'. Processing next segment.");
                appendNextVideoSegment();
            });
            audioSourceBuffer.addEventListener('error', (e) => {
                console.error("Audio SourceBuffer error:", e);
                showNotification("Audio playback error. Please try again.", "error-message", 0);
                if (mediaSource && mediaSource.readyState === 'open') {
                    try { mediaSource.endOfStream('decode'); } catch(err) { console.warn("Error ending MediaSource on audio SB error:", err); }
                }
                resetUIForNewSession();
            });

            appendNextVideoSegment(); // After SourceBuffers are ready, try to append any queued segments

        } catch (e) {
            console.error("Error adding source buffer or incompatible codecs:", e);
            showNotification("Your browser does not support the video/audio format or codecs. Try a different browser.", "error-message", 0);
            if (mediaSource && mediaSource.readyState === 'open') {
                try { mediaSource.endOfStream('decode'); } catch(err) { console.warn("Error ending MediaSource due to codec error:", err); }
            }
            resetUIForNewSession();
        }
    });

    mediaSource.addEventListener('sourceended', () => {
        isMediaSourceOpen = false;
        console.log("MediaSource 'sourceended' event fired.");
    });
    mediaSource.addEventListener('sourceclose', () => {
        isMediaSourceOpen = false;
        console.log("MediaSource 'sourceclose' event fired.");
    });
}

function appendNextVideoSegment() {
    if (!isMediaSourceOpen || segmentQueue.length === 0) {
        if (!isMediaSourceOpen) console.log("appendNextVideoSegment skipped: MediaSource not open yet.");
        if (segmentQueue.length === 0) console.log("appendNextVideoSegment skipped: Segment queue is empty.");
        return;
    }
    if (appendingInProgress) {
        console.log("appendNextVideoSegment skipped: An append operation is already in progress.");
        return;
    }

    const segmentObj = segmentQueue.shift();
    const segmentData = segmentObj.data;
    const segmentType = segmentObj.segment_type;
    const streamType = segmentObj.stream_type;
    const segmentNumber = segmentObj.segment_number;

    let targetSourceBuffer = null;
    if (streamType === "video") targetSourceBuffer = videoSourceBuffer;
    else if (streamType === "audio") targetSourceBuffer = audioSourceBuffer;
    else {
        console.warn(`Unknown stream type: ${streamType}. Cannot append segment #${segmentNumber}.`);
        appendNextVideoSegment();
        return;
    }

    if (!targetSourceBuffer) {
        console.error(`SourceBuffer for ${streamType} is not initialized. Re-queueing segment #${segmentNumber}.`);
        segmentQueue.unshift(segmentObj);
        return;
    }
    if (targetSourceBuffer.updating) {
        console.warn(`SourceBuffer for ${streamType} is busy. Re-queueing segment #${segmentNumber}.`);
        segmentQueue.unshift(segmentObj);
        return;
    }

    appendingInProgress = true;
    console.log(`Attempting to append ${streamType} ${segmentType} segment #${segmentNumber}. Queue size after shift: ${segmentQueue.length}`);

    try {
        if (segmentType === "init") {
            if (streamType === "video" && !videoInitReceived) {
                targetSourceBuffer.appendBuffer(segmentData);
                videoInitReceived = true;
                console.log(`Video init segment #${segmentNumber} appended.`);
            } else if (streamType === "audio" && !audioInitReceived) {
                targetSourceBuffer.appendBuffer(segmentData);
                audioInitReceived = true;
                console.log(`Audio init segment #${segmentNumber} appended.`);
            } else {
                console.warn(`${streamType} init segment #${segmentNumber} already received or invalid state. Skipping append.`);
                appendingInProgress = false;
                appendNextVideoSegment();
                return;
            }
        } else {
            targetSourceBuffer.appendBuffer(segmentData);
        }

        // --- Playback Trigger Logic (MODIFIED for Autoplay) ---
        if (videoInitReceived && audioInitReceived && !hasAttemptedVideoPlayback) {
            console.log("Both video and audio init segments received. Attempting to auto-play video (muted initially).");
            hasAttemptedVideoPlayback = true;

            outputVideo.play()
                .then(() => {
                    console.log("Video auto-play initiated (muted).");
                    showNotification("Video is playing (muted). Attempting to unmute...", "success-message", 3000);
                    // Attempt to unmute after a short delay or when some playback has occurred
                    // This is still subject to browser policies.
                    setTimeout(() => {
                        if (outputVideo.muted) {
                            outputVideo.muted = false;
                            console.log("Attempted to unmute video.");
                            if (!outputVideo.muted) {
                                showNotification("Video is now playing with sound.", "success-message", 5000);
                            } else {
                                showNotification("Video is playing but remains muted by browser policy. Click video to unmute.", "info-message", 0);
                            }
                        }
                    }, 500); // Small delay before attempting unmute
                })
                .catch(e => {
                    console.warn("Video auto-play prevented:", e);
                    showNotification("Video auto-play prevented by browser. Click the video to play.", "error-message", 0);
                    // Optionally, add a visible 'play' button here if autoplay fails
                    // document.getElementById("manualPlayButton").style.display = 'block';
                });
        }

    } catch (e) {
        console.error(`Error appending ${streamType} ${segmentType} buffer (segment #${segmentNumber}):`, e);
        showNotification(`Error appending ${streamType} segment. Playback might be interrupted.`, "error-message", 0);
        appendingInProgress = false;
    }
}


// --- User Interaction Functions ---
window.startLipSync = async function() {
    const imageFile = imageInput.files[0];
    const enhanceFace = enhanceFaceCheckbox.checked;

    if (!imageFile) {
        showNotification("Please select an image file.", "error-message", 5000);
        return;
    }
    if (socket.readyState !== WebSocket.OPEN) {
        showNotification("WebSocket is not connected. Please refresh the page.", "error-message", 0);
        return;
    }

    showNotification("Sending image and initializing...", "status-message", 0);
    resetUIForNewSession();
    try {
        const base64Image = await getBase64(imageFile);
        const initMessage = {
            type: "image_init",
            base64_content: base64Image,
            enhance_face: enhanceFace,
            use_cpu: false
        };
        console.log("Sending image_init message to server.");
        socket.send(JSON.stringify(initMessage));
        startLipSyncButton.disabled = true;
    } catch (error) {
        showNotification(`Error processing image file: ${error.message}`, "error-message", 0);
        console.error("Error in startLipSync:", error);
        resetUIForNewSession();
    }
};

window.startRecording = async function() {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
        showNotification("Already recording.", "info-message", 2000);
        return;
    }
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm; codecs=opus' });
        audioChunks = [];
        recordedAudioPlayback.src = "";
        playRecordedAudioButton.disabled = true;
        isAudioStreamReady = false;

        mediaRecorder.ondataavailable = async (event) => {
            if (event.data.size > 0) {
                audioChunks.push(event.data);
                if (isAudioStreamReady && socket.readyState === WebSocket.OPEN) {
                    const base64Audio = await getBase64(event.data);
                    const audioChunkMessage = { type: "audio_chunk", base64_content: base64Audio };
                    socket.send(JSON.stringify(audioChunkMessage));
                } else if (!isAudioStreamReady) {
                    console.warn("Audio data available but server not ready for audio stream. Buffering locally.");
                }
            }
        };

        mediaRecorder.onstop = async () => {
            isAudioStreamReady = false;
            recordedAudioBlob = new Blob(audioChunks, { type: 'audio/webm; codecs=opus' });
            recordedAudioPlayback.src = URL.createObjectURL(recordedAudioBlob);
            playRecordedAudioButton.disabled = false;
            showNotification("Recording stopped. Audio available for playback.", "success-message", 3000);

            if (socket.readyState === WebSocket.OPEN) {
                socket.send(JSON.stringify({ type: "end_audio_stream" }));
                showNotification("Signaled end of audio stream to server.", "info-message", 3000);
            }
            outputVideo.addEventListener('ended', () => {
                if (outputVideo.src.startsWith('blob:')) {
                    URL.revokeObjectURL(outputVideo.src);
                    outputVideo.src = "";
                    console.log("Revoked outputVideo blob URL.");
                }
            }, { once: true });
            recordedAudioPlayback.addEventListener('ended', () => {
                if (recordedAudioPlayback.src.startsWith('blob:')) {
                    URL.revokeObjectURL(recordedAudioPlayback.src);
                    recordedAudioPlayback.src = "";
                    console.log("Revoked recordedAudioPlayback blob URL.");
                }
            }, { once: true });
        };

        socket.send(JSON.stringify({ type: "start_audio_stream" }));
        showNotification("Requesting audio stream initiation from server...", "status-message", 0);

        startRecordingButton.disabled = true;
        stopRecordingButton.disabled = false;

    } catch (error) {
        showNotification(`Error starting recording: ${error.message}`, "error-message", 0);
        console.error("Error starting recording:", error);
        startRecordingButton.disabled = false;
        stopRecordingButton.disabled = true;
        isAudioStreamReady = false;
    }
};

window.stopRecording = function() {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
        mediaRecorder.stop();
        console.log("MediaRecorder stopped.");
        startRecordingButton.disabled = true;
        stopRecordingButton.disabled = true;
    } else {
        showNotification("No active recording to stop.", "info-message", 2000);
    }
};

window.playRecordedAudio = function() {
    if (recordedAudioPlayback.src) {
        recordedAudioPlayback.play().catch(e => {
            showNotification(`Error playing audio: ${e.message}`, "error-message", 3000);
            console.error("Error playing recorded audio:", e);
        });
    } else {
        showNotification("No recorded audio to play.", "info-message", 2000);
    }
};

function resetUIForNewSession() {
    console.log("Resetting UI for new session...");
    startLipSyncButton.disabled = false;
    startRecordingButton.disabled = true;
    stopRecordingButton.disabled = true;
    playRecordedAudioButton.disabled = true;
    // Removed playOutputVideoButton.disabled = true;
    imageInput.value = '';
    outputVideo.style.display = 'none';

    if (mediaSourceUrl) {
        URL.revokeObjectURL(mediaSourceUrl);
        mediaSourceUrl = null;
        console.log("Revoked old MediaSource blob URL.");
    }
    outputVideo.src = "";
    recordedAudioPlayback.src = "";

    if (mediaSource && mediaSource.readyState === 'open') {
        try {
            mediaSource.endOfStream();
            console.log("MediaSource.endOfStream() called during UI reset.");
        } catch (e) {
            console.warn("Error calling endOfStream during UI reset (may be already ended or detached):", e);
        }
    }
    if (videoSourceBuffer && mediaSource && mediaSource.sourceBuffers.includes(videoSourceBuffer)) {
        try {
            mediaSource.removeSourceBuffer(videoSourceBuffer);
            console.log("Video SourceBuffer removed.");
        } catch (e) {
            console.warn("Error removing video SourceBuffer during UI reset:", e);
        }
    }
    if (audioSourceBuffer && mediaSource && mediaSource.sourceBuffers.includes(audioSourceBuffer)) {
        try {
            mediaSource.removeSourceBuffer(audioSourceBuffer);
            console.log("Audio SourceBuffer removed.");
        } catch (e) {
            console.warn("Error removing audio SourceBuffer during UI reset:", e);
        }
    }

    mediaSource = null;
    videoSourceBuffer = null;
    audioSourceBuffer = null;
    segmentQueue = [];
    isMediaSourceOpen = false;
    appendingInProgress = false;
    recordedAudioBlob = null;
    videoInitReceived = false;
    audioInitReceived = false;
    isAudioStreamReady = false;
    mediaSourceInitialized = false;
    hasAttemptedVideoPlayback = false; // Reset this flag for a completely new playback attempt

    clearTimeout(notificationTimeout);
    notificationDiv.classList.add("notification-hidden");
    notificationDiv.textContent = "";

    showNotification("Ready for a new session. Select image and click '1. Send Image & Initialize'.", "status-message", 5000);
}


// --- Initial State Setup and base64js Polyfill ---
document.addEventListener('DOMContentLoaded', () => {
    if (typeof window.base64js === 'undefined') {
        console.warn("base64js library not found, using simple polyfill. Consider loading a robust library.");
        window.base64js = {
            toByteArray: function (base64) {
                try {
                    const binary_string = window.atob(base64);
                    const len = binary_string.length;
                    const bytes = new Uint8Array(len);
                    for (let i = 0; i < len; i++) {
                        bytes[i] = binary_string.charCodeAt(i);
                    }
                    return bytes;
                } catch (e) {
                    console.error("Error in base64js.toByteArray polyfill:", e);
                    throw new Error("Failed to decode base64 string.");
                }
            }
        };
    }
    resetUIForNewSession();
});